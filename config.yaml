run_name: "reduced_feat_no_action_feat"

player_count: 1

p0_model:
  name: "reduced_feat_no_action_feat_p0"
  type: 'transformer'
  hyperparams:
    hidden_dim: 512
    num_layers: 2
    attention_heads: 4
    max_sequence_length: 5
  frames_per_observation: 5
  reaction_delay: 1
  learning_rate: 1e-4
  reward_gamma: .5
  atk_preframes: 2
  whiff_reward: 0
  full_reward: True
  reward_columns:
    0:
      "p_0_health": 1
      "p_1_health": -1
  reward_falloff: 25
  state_features: ['x_spac','y_spac','moon','moon_st','motion','motion_type','gauge']
  action_feature: False
  input_mask:


p1_model:
  name: "reduced_feat_no_action_feat_p1"
  type: 'transformer'
  hyperparams:
    hidden_dim: 512
    num_layers: 2
    attention_heads: 4,
    max_sequence_length: 5
  frames_per_observation: 5
  reaction_delay: 1
  learning_rate: 1e-4
  reward_gamma: .5
  atk_preframes: 2
  whiff_reward: 0
  full_reward: True
  reward_columns:
    0:
      "p_0_health": 1
      "p_1_health": -1
  reward_falloff: 25
  state_features: ['x_spac','y_spac','moon','moon_st','motion','motion_type','gauge']
  action_feature: False
  input_mask:


data_path: "../data"
minmax_file: "eval/no_cat_less_minmax.json"
count_save: 1
# explore
probability_action: False
final_epsilon:  0
initial_epsilon: 1
epsilon_decay: 200
explore_reset: 10
eps_explore_threshold: 0


# training
episode_sample_size: 1
last_episode_only: False
batch_size: 512
epochs: 1
tau: 200

# inputs
directions:
  - ["1","3"]
  - ["2","2"]
  - ["3","1"]
  - ["4","6"]
  - ["5","5"]
  - ["6","4"]
  - ["7","9"]
  - ["8","8"]
  - ["9","7"]

buttons:
  - "a"
  - "b"
  - "c"
  - "d"


timer_max: 9999

log_level: DEBUG

save_model: True



